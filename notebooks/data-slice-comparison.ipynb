{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import itertools\n",
    "import random\n",
    "import copy\n",
    "from datetime import datetime\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from src.helpers import io\n",
    "from src.classes.dataset import Dataset\n",
    "from src.classes.annotation_set import AnnotationSet\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt-multi_turn_relationship: 0 / 10127 failed due to invalid annotations.\n",
      "prompt-interaction_features: 0 / 10127 failed due to invalid annotations.\n",
      "turn-sensitive_use_flags: 0 / 10127 failed due to invalid annotations.\n",
      "turn-topic: 1 / 10127 failed due to invalid annotations.\n",
      "response-interaction_features: 0 / 10127 failed due to invalid annotations.\n",
      "prompt-function_purpose: 6 / 10127 failed due to invalid annotations.\n",
      "prompt-media_format: 0 / 10127 failed due to invalid annotations.\n",
      "response-media_format: 0 / 10127 failed due to invalid annotations.\n",
      "response-answer_form: 0 / 10127 failed due to invalid annotations.\n"
     ]
    }
   ],
   "source": [
    "# FILL IN:\n",
    "PATH_TO_DATASET = \"../data/static/wildchat4k-raw.json\"\n",
    "DATASET_ID = \"wildchat_1m\"\n",
    "PATH_TO_ANNOTATIONS_DIR = \"../res/gpto3mini-json-wildchat\"\n",
    "OUTDIR = \"data/annotation_analysis_v0/data-slice-comparison\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "# Load dataset (w/o annotations)\n",
    "dataset = Dataset.load(PATH_TO_DATASET)\n",
    "\n",
    "# Load annotations into dataset\n",
    "for fpath in io.listdir_nohidden(PATH_TO_ANNOTATIONS_DIR):\n",
    "    annotation_set = AnnotationSet.load_automatic(path=fpath, source=\"automatic_v0\")\n",
    "    dataset.add_annotations(annotation_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General-purpose data slice comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset by group function\n",
    "def split_dataset_by(dataset, group_fn):\n",
    "    groups = defaultdict(list)\n",
    "    for conv in dataset.data:\n",
    "        group = group_fn(conv)\n",
    "        groups[group].append(conv)\n",
    "    return {g: Dataset(dataset_id=f\"{dataset.dataset_id}_{g}\", data=convs) for g, convs in groups.items()}\n",
    "\n",
    "# Compare each group to baseline\n",
    "def compare_annotations_to_baseline(group_datasets, baseline_dataset, annotation_tasks, annotation_source=\"automatic_v0\"):\n",
    "    def get_label_counts(dset, task_name, level):\n",
    "        counter = Counter()\n",
    "        for conv in dset.data:\n",
    "            for msg in conv.conversation:\n",
    "                if level == \"conversation\":\n",
    "                    label = getattr(conv, task_name, None)\n",
    "                else:\n",
    "                    if msg.role == \"user\" and level == \"prompt\":\n",
    "                        key = f\"{annotation_source}-prompt_{task_name}\"\n",
    "                    elif msg.role == \"assistant\" and level == \"response\":\n",
    "                        key = f\"{annotation_source}-response_{task_name}\"\n",
    "                    elif level == \"turn\":\n",
    "                        key = f\"{annotation_source}-turn_{task_name}\"\n",
    "                    else:\n",
    "                        continue\n",
    "                    if key in msg.metadata:\n",
    "                        label = msg.metadata[key].value\n",
    "                    else:\n",
    "                        label = None\n",
    "                if label:\n",
    "                    if isinstance(label, list):\n",
    "                        counter.update(label)\n",
    "                    else:\n",
    "                        counter[label] += 1\n",
    "        return counter\n",
    "\n",
    "    baseline_distributions = {\n",
    "        (task, level): get_label_counts(baseline_dataset, task, level)\n",
    "        for (task, level) in annotation_tasks\n",
    "    }\n",
    "\n",
    "    comparison_results = {}\n",
    "    for group_name, group_dataset in group_datasets.items():\n",
    "        group_results = {}\n",
    "        for (task, level) in annotation_tasks:\n",
    "            baseline = baseline_distributions[(task, level)]\n",
    "            group = get_label_counts(group_dataset, task, level)\n",
    "            total_base = sum(baseline.values())\n",
    "            total_group = sum(group.values())\n",
    "\n",
    "            all_labels = set(baseline.keys()) | set(group.keys())\n",
    "            differences = []\n",
    "            for label in all_labels:\n",
    "                base_pct = (baseline[label] / total_base) * 100 if total_base else 0\n",
    "                group_pct = (group[label] / total_group) * 100 if total_group else 0\n",
    "                diff = round(group_pct - base_pct, 2)\n",
    "                differences.append((label, diff, group_pct, base_pct))\n",
    "\n",
    "            differences.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "            group_results[(task, level)] = differences\n",
    "\n",
    "        comparison_results[group_name] = group_results\n",
    "\n",
    "    return comparison_results\n",
    "\n",
    "# Visualization: Diverging bar chart for one group's difference from baseline\n",
    "def plot_differences_for_group(group_name, group_diff_data, baseline_label, comparison_label, outdir=OUTDIR):\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    for (task, level), diffs in group_diff_data.items():\n",
    "        if not diffs:\n",
    "            print(f\"[Skipped] No data available to plot for {task} @ {level}\")\n",
    "            continue\n",
    "\n",
    "        labels, differences, group_pcts, base_pcts = zip(*diffs)\n",
    "        colors = [\"green\" if diff > 0 else \"red\" for diff in differences]\n",
    "\n",
    "        plt.figure(figsize=(10, max(6, len(labels) * 0.5)))\n",
    "        y_pos = np.arange(len(labels))\n",
    "        bars = plt.barh(y_pos, differences, color=colors)\n",
    "        plt.yticks(y_pos, labels)\n",
    "        plt.axvline(0, color=\"black\", linewidth=0.8)\n",
    "        plt.title(f\"{comparison_label} vs {baseline_label}\\nTop Differences for {task} @ {level}\")\n",
    "        plt.xlabel(\"Percentage Difference from Baseline\")\n",
    "        plt.gca().invert_yaxis()\n",
    "\n",
    "        for i, bar in enumerate(bars):\n",
    "            plt.text(\n",
    "                bar.get_width() + (0.5 if bar.get_width() > 0 else -0.5),\n",
    "                bar.get_y() + bar.get_height() / 2,\n",
    "                f\"{differences[i]:+.1f}%\",\n",
    "                va='center', ha='left' if bar.get_width() > 0 else 'right', fontsize=9\n",
    "            )\n",
    "\n",
    "        safe_group = ''.join([w[0].upper() for w in comparison_label.split()])\n",
    "        safe_base = ''.join([w[0].upper() for w in baseline_label.split()])\n",
    "        fname = f\"diff_{safe_group}{safe_base}_{level}_{task}.png\"\n",
    "        plot_path = os.path.join(outdir, fname)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "        print(f\"Saved plot: {plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use geography as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plot: data/annotation_analysis_v0/data-slice-comparison/diff_CUS_prompt_function_purpose.png\n",
      "Saved plot: data/annotation_analysis_v0/data-slice-comparison/diff_CUS_prompt_interaction_features.png\n",
      "Saved plot: data/annotation_analysis_v0/data-slice-comparison/diff_CUS_prompt_media_format.png\n",
      "[Skipped] No data available to plot for answer_form @ response\n",
      "[Skipped] No data available to plot for interaction_features @ response\n",
      "[Skipped] No data available to plot for media_format @ response\n",
      "Saved plot: data/annotation_analysis_v0/data-slice-comparison/diff_CUS_turn_topic.png\n",
      "Saved plot: data/annotation_analysis_v0/data-slice-comparison/diff_CUS_turn_sensitive_use_flags.png\n"
     ]
    }
   ],
   "source": [
    "# === Custom Group Definitions ===\n",
    "# Split by country (user types, different datasets, language?, )\n",
    "grouped_by_country = split_dataset_by(\n",
    "    dataset,\n",
    "    lambda conv: conv.geography.split(\";\")[0].strip() if conv.geography else \"Unknown\"\n",
    ")\n",
    "\n",
    "# Define baseline and comparison groups\n",
    "baseline_names = [\"United States\"]\n",
    "comparison_names = [\"China\"]\n",
    "\n",
    "baseline_dataset = Dataset(\n",
    "    dataset_id=\"baseline_group\",\n",
    "    data=list(itertools.chain.from_iterable([\n",
    "        grouped_by_country[c].data for c in baseline_names if c in grouped_by_country\n",
    "    ]))\n",
    ")\n",
    "comparison_dataset = Dataset(\n",
    "    dataset_id=\"comparison_group\",\n",
    "    data=list(itertools.chain.from_iterable([\n",
    "        grouped_by_country[c].data for c in comparison_names if c in grouped_by_country\n",
    "    ]))\n",
    ")\n",
    "\n",
    "annotation_tasks = [\n",
    "    (\"function_purpose\", \"prompt\"),\n",
    "    (\"interaction_features\", \"prompt\"),\n",
    "    (\"media_format\", \"prompt\"),\n",
    "    (\"answer_form\", \"response\"),\n",
    "    (\"interaction_features\", \"response\"),\n",
    "    (\"media_format\", \"response\"),\n",
    "    (\"topic\", \"turn\"),\n",
    "    (\"sensitive_use_flags\", \"turn\"),\n",
    "]\n",
    "\n",
    "comparison_results = compare_annotations_to_baseline(\n",
    "    group_datasets={\"ComparisonGroup_vs_Baseline\": comparison_dataset},\n",
    "    baseline_dataset=baseline_dataset,\n",
    "    annotation_tasks=annotation_tasks,\n",
    "    annotation_source=\"automatic_v0\"\n",
    ")\n",
    "\n",
    "plot_differences_for_group(\n",
    "    group_name=\"ComparisonGroup_vs_Baseline\",\n",
    "    group_diff_data=comparison_results[\"ComparisonGroup_vs_Baseline\"],\n",
    "    baseline_label=\", \".join(baseline_names),\n",
    "    comparison_label=\", \".join(comparison_names)\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
