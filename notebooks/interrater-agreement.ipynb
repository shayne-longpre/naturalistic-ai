{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "aa5a6644-4fec-4cd3-bc93-abc0aa327091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "import random\n",
    "from typing import List, Any, Dict, Tuple\n",
    "import copy\n",
    "from datetime import datetime\n",
    "from collections import Counter, defaultdict\n",
    "from scipy import stats\n",
    "from tabulate import tabulate\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from src.scripts import run_fake_data_test\n",
    "from src.helpers.visualisation import barplot_distribution, plot_confusion_matrix, tabulate_annotation_pair_summary, analyze_pair_annotations\n",
    "from src.helpers.io import read_json\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "43672ec7-e60f-493c-bc24-265d7f4bafe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_fields_prev = [\n",
    "    \"multi_turn_relationship\",\n",
    "    \"media_format\",\n",
    "    \"topic\",\n",
    "    \"function_purpose\",\n",
    "    \"anthropomorphization\",\n",
    "    \"restricted_flags\",\n",
    "]\n",
    "response_fields_prev = [\n",
    "    \"answer_form\",\n",
    "    \"self_disclosure\",\n",
    "    \"topic_response\",\n",
    "    \"media_format_response\",\n",
    "    \"restricted_flags_response\",\n",
    "]\n",
    "\n",
    "prompt_fields_new = [\n",
    "    \"prompt_multi_turn_relationship\",\n",
    "    \"prompt_media_format\",\n",
    "    \"prompt_interaction_features\",\n",
    "    \"prompt_function_purpose\",\n",
    "    \"turn_topic\",\n",
    "    \"turn_sensitive_use_flags\",\n",
    "]\n",
    "response_fields_new = [\n",
    "    \"response_answer_form\",\n",
    "    \"response_media_format\",\n",
    "    \"response_interaction_features\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a762bbb2-5baf-466c-a150-56cae1e94165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading conversations from ../data/sample120.json\n",
      "Loaded 120 conversations.\n",
      "Updated file: combined.json\n",
      "Added conversation IDs to 1 files\n",
      "Split records into two folders:\n",
      "  - ../data/labelstudio_outputs_split1_v2/: Contains 0 records with unique conversation IDs\n",
      "  - ../data/labelstudio_outputs_split2_v2/: Contains 83 records with duplicate conversation IDs\n",
      "starttinginsdgljsdfjksdfjl\n",
      "prompt_media_format\n",
      "prompt_function_purpose\n",
      "prompt_multi_turn_relationship\n",
      "prompt_interaction_features\n",
      "turn_sensitive_use_flags\n",
      "turn_topic\n",
      "response_media_format\n",
      "response_answer_form\n",
      "prompt_media_format\n",
      "prompt_function_purpose\n",
      "prompt_multi_turn_relationship\n",
      "prompt_interaction_features\n",
      "turn_sensitive_use_flags\n",
      "turn_topic\n",
      "response_media_format\n",
      "response_answer_form\n",
      "\n",
      "gpt4o-json\n",
      "\n",
      "prompt-multi_turn_relationship: 2 / 597 failed due to invalid annotations.\n",
      "prompt_multi_turn_relationship\n",
      "prompt-interaction_features: 1 / 597 failed due to invalid annotations.\n",
      "prompt_interaction_features\n",
      "turn-sensitive_use_flags: 0 / 597 failed due to invalid annotations.\n",
      "turn_sensitive_use_flags\n",
      "turn-topic: 14 / 597 failed due to invalid annotations.\n",
      "turn_topic\n",
      "response-interaction_features: 0 / 597 failed due to invalid annotations.\n",
      "response_interaction_features\n",
      "prompt-function_purpose: 4 / 597 failed due to invalid annotations.\n",
      "prompt_function_purpose\n",
      "prompt-media_format: 19 / 597 failed due to invalid annotations.\n",
      "prompt_media_format\n",
      "response-media_format: 5 / 597 failed due to invalid annotations.\n",
      "response_media_format\n",
      "response-answer_form: 1 / 597 failed due to invalid annotations.\n",
      "response_answer_form\n",
      "\n",
      "gpt4o-free\n",
      "\n",
      "prompt-multi_turn_relationship: 0 / 597 failed due to invalid annotations.\n",
      "prompt_multi_turn_relationship\n",
      "prompt-interaction_features: 1 / 597 failed due to invalid annotations.\n",
      "prompt_interaction_features\n",
      "turn-sensitive_use_flags: 1 / 597 failed due to invalid annotations.\n",
      "turn_sensitive_use_flags\n",
      "turn-topic: 5 / 597 failed due to invalid annotations.\n",
      "turn_topic\n",
      "response-interaction_features: 0 / 597 failed due to invalid annotations.\n",
      "response_interaction_features\n",
      "prompt-function_purpose: 8 / 597 failed due to invalid annotations.\n",
      "prompt_function_purpose\n",
      "prompt-media_format: 7 / 597 failed due to invalid annotations.\n",
      "prompt_media_format\n",
      "response-media_format: 1 / 597 failed due to invalid annotations.\n",
      "response_media_format\n",
      "prompt-function_purpose: 8 / 597 failed due to invalid annotations.\n",
      "prompt_function_purpose2\n",
      "response-answer_form: 0 / 597 failed due to invalid annotations.\n",
      "response_answer_form\n",
      "\n",
      "gpto3mini-json\n",
      "\n",
      "prompt-multi_turn_relationship: 0 / 597 failed due to invalid annotations.\n",
      "prompt_multi_turn_relationship\n",
      "prompt-interaction_features: 0 / 597 failed due to invalid annotations.\n",
      "prompt_interaction_features\n",
      "turn-sensitive_use_flags: 0 / 597 failed due to invalid annotations.\n",
      "turn_sensitive_use_flags\n",
      "turn-topic: 0 / 597 failed due to invalid annotations.\n",
      "turn_topic\n",
      "response-interaction_features: 0 / 597 failed due to invalid annotations.\n",
      "response_interaction_features\n",
      "prompt-function_purpose: 2 / 597 failed due to invalid annotations.\n",
      "prompt_function_purpose\n",
      "prompt-media_format: 0 / 597 failed due to invalid annotations.\n",
      "prompt_media_format\n",
      "response-media_format: 0 / 597 failed due to invalid annotations.\n",
      "response_media_format\n",
      "response-answer_form: 0 / 597 failed due to invalid annotations.\n",
      "response_answer_form\n",
      "\n",
      "gpto3mini-free\n",
      "\n",
      "prompt-multi_turn_relationship: 0 / 597 failed due to invalid annotations.\n",
      "prompt_multi_turn_relationship\n",
      "prompt-interaction_features: 0 / 597 failed due to invalid annotations.\n",
      "prompt_interaction_features\n",
      "turn-sensitive_use_flags: 0 / 597 failed due to invalid annotations.\n",
      "turn_sensitive_use_flags\n",
      "turn-topic: 0 / 597 failed due to invalid annotations.\n",
      "turn_topic\n",
      "response-interaction_features: 0 / 597 failed due to invalid annotations.\n",
      "response_interaction_features\n",
      "prompt-function_purpose: 1 / 597 failed due to invalid annotations.\n",
      "prompt_function_purpose\n",
      "prompt-media_format: 0 / 597 failed due to invalid annotations.\n",
      "prompt_media_format\n",
      "response-media_format: 0 / 597 failed due to invalid annotations.\n",
      "response_media_format\n",
      "response-answer_form: 0 / 597 failed due to invalid annotations.\n",
      "response_answer_form\n"
     ]
    }
   ],
   "source": [
    "dset = run_fake_data_test.run_automatic_analysis_v0(\"../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ce4059bd-c25d-48f3-8f82-7dca6f518958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_interrater_comparison(\n",
    "    dataset, \n",
    "    task_name,\n",
    "    annotation_source_1,\n",
    "    annotation_source_2,\n",
    "):\n",
    "    info_to_plot1 = dset.get_annotation_distribution(name=task_name, level=\"message\", annotation_source=annotation_source_1)\n",
    "    info_to_plot2 = dset.get_annotation_distribution(name=task_name, level=\"message\", annotation_source=annotation_source_2)\n",
    "    info_to_plot1b = dset.get_annotation_distribution(name=task_name, level=\"message\", annotation_source=annotation_source_1, annotation_as_list_type=True)\n",
    "    info_to_plot2b = dset.get_annotation_distribution(name=task_name, level=\"message\", annotation_source=annotation_source_2, annotation_as_list_type=True)\n",
    "\n",
    "    outdir = f\"../data/annotation_analysis_v0/{annotation_source_1}--{annotation_source_2}/{task_name}\"\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    fig = barplot_distribution(\n",
    "        {\"Split1\": info_to_plot1, \"Split2\": info_to_plot2}, normalize=True, \n",
    "        xlabel=task_name, ylabel=\"Proportion\", title=\"\",\n",
    "        output_path=f\"{outdir}/barchart.png\", order=\"descending\")\n",
    "    \n",
    "    fig_b = barplot_distribution(\n",
    "        {\"Split1\": info_to_plot1b, \"Split2\": info_to_plot2b}, normalize=True, \n",
    "        xlabel=task_name, ylabel=\"Proportion\", title=\"\",\n",
    "        output_path=f\"{outdir}/multilabel_barchart.png\", order=\"descending\")\n",
    "\n",
    "    info_to_plot_cm, agreement_metrics, paired_values = dataset.get_joint_distribution(\n",
    "        annotations1=(task_name, annotation_source_1), \n",
    "        annotations2=(task_name, annotation_source_2), \n",
    "        level=\"message\",\n",
    "        compute_disagreement=True,\n",
    "        verbose=True\n",
    "    )\n",
    "    # print(info_to_plot_cm)\n",
    "\n",
    "    fig2 = plot_confusion_matrix(\n",
    "        info_to_plot_cm, normalize=True, xlabel=\"\", ylabel=\"\", title=\"Confusion Matrix\",\n",
    "        output_path=f\"{outdir}/confusion_matrix.png\")\n",
    "\n",
    "    # print(paired_values[0:3])\n",
    "    df = analyze_pair_annotations(paired_values)\n",
    "    df.to_csv(f\"{outdir}/pair_frequencies.csv\", index=False, quoting=csv.QUOTE_NONNUMERIC)\n",
    "\n",
    "    print()\n",
    "    print(f\"-----------------{task_name}-----------------\")\n",
    "    print(agreement_metrics)\n",
    "    print(tabulate_annotation_pair_summary(df, 20))\n",
    "    print(len(df))\n",
    "    print()\n",
    "    return paired_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1200b560-71a4-4a7e-907a-7e207531bdd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "84d9afd7-deb5-4511-a662-b82f3b18654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_annotations = {}\n",
    "# for feature in prompt_fields_new:\n",
    "#     task_annotations[feature] = run_interrater_comparison(dset, feature, \"gpt4o_json_full\", \"gpt4o_free_full\")\n",
    "#     # break\n",
    "# for feature in response_fields_new:\n",
    "#     task_annotations[feature] = run_interrater_comparison(dset, feature, \"gpt4o_json_full\", \"gpt4o_free_full\")\n",
    "#     # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "57efdab0-9368-46d1-a0f4-b5e58d8faa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_ids = []\n",
    "orig_sample = read_json(\"../data/sample120.json\")\n",
    "for datum in orig_sample[\"data\"]:\n",
    "    for turn in datum[\"conversation\"]:\n",
    "        ex_ids.append(datum[\"conversation_id\"] + \"-\" + str(turn[\"turn\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fba8943-fc05-4c62-8297-63a8ab71e919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbffae1-2dc9-4084-ac72-ceeda10e8c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6e7ac89f-388d-4413-bc82-94a5511d895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatic_variants = [\n",
    "#     \"gpt4o_json_full\",\n",
    "#     # \"gpt4o_free_full\",\n",
    "#     \"gpto3mini_json_full\",\n",
    "#     # \"gpto3mini_free_full\",\n",
    "# ]\n",
    "# focus_keys = [(model_key, field_name) for model_key in automatic_variants for field_name in prompt_fields_new]\n",
    "# focus_keys.extend([(model_key, field_name) for model_key in automatic_variants for field_name in response_fields_new])\n",
    "# focus_keys.extend([(split_key, field_name) for split_key in [\"split1\", \"split2\"] for field_name in prompt_fields_new])\n",
    "# focus_keys.extend([(split_key, field_name) for split_key in [\"split1\", \"split2\"] for field_name in response_fields_new])\n",
    "# focus_metadatas = dset.extract_conversation_metadata_by_ids(\n",
    "#     ex_ids,\n",
    "#     annotation_keys=focus_keys,\n",
    "#     level=\"message\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "caf6e2f7-3cb4-4953-a90c-a0e6f5e65cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_info_for_turn(\n",
    "    ex_idx_turn,\n",
    "):\n",
    "\n",
    "    ex_idx, turn = ex_idx_turn.split(\"-\")\n",
    "    turn = int(turn)\n",
    "    message = dset.id_lookup(ex_idx_turn, level=\"message\")[ex_idx_turn].to_dict()\n",
    "    role = message['role']\n",
    "    # relevant_keys = prompt_fields_new if role == \"user\" else response_fields_new\n",
    "    relevant_keys = prompt_fields_new + response_fields_new\n",
    "    task_to_source_to_vals = defaultdict(dict)\n",
    "    for key in message[\"metadata\"].keys():\n",
    "        source, task = key.split(\"-\")\n",
    "        if task in relevant_keys:\n",
    "            task_to_source_to_vals[task][source] = message[\"metadata\"][key]\n",
    "\n",
    "    print(f\"IDX: {ex_idx} | Turn: {turn} | Role: {role}\")\n",
    "    print(f\"-------------------------------------------\")\n",
    "    for task, source_vals in task_to_source_to_vals.items():\n",
    "        print()\n",
    "        print(f\"TASK: {task}\")\n",
    "        for source, val in source_vals.items():\n",
    "            src_info = val[\"annotator\"] if \"split\" in source else source\n",
    "            print(f\"{src_info}:   {val['value']}\")\n",
    "\n",
    "    print(\"\\n****** Message Content:******\")\n",
    "    print(message[\"content\"])\n",
    "    print()\n",
    "\n",
    "    if turn > 0:\n",
    "        print(\"\\n****** Previous Turn Message Content:******\")\n",
    "        prev_message = dset.id_lookup(ex_idx + \"-\" + str(turn-1), level=\"message\")[ex_idx + \"-\" + str(turn-1)].to_dict()\n",
    "        print(prev_message[\"content\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c48a52d2-d8bc-4323-9bca-7c73eb922a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDX: wildchat_1d31bdda8c40f114afa0aad43e02a3c9 | Turn: 0 | Role: user\n",
      "-------------------------------------------\n",
      "\n",
      "TASK: prompt_media_format\n",
      "megan:   ['Formatted enumeration / itemization', 'Likely retrieved / pasted content', 'Natural language']\n",
      "niloofar:   ['Formatted enumeration / itemization', 'Likely retrieved / pasted content', 'Math / symbols', 'Natural language']\n",
      "gpt4o_json:   ['Natural language', 'Formatted enumeration/itemization']\n",
      "gpt4o_free:   ['Natural language', 'Formatted enumeration/itemization (bullets/lists)']\n",
      "gpto3mini_json:   ['Natural language', 'Formatted enumeration/itemization']\n",
      "gpto3mini_free:   ['Natural language', 'Formatted enumeration/itemization (bullets/lists)']\n",
      "\n",
      "TASK: prompt_function_purpose\n",
      "megan:   ['Content generation: Prompts for another AI system']\n",
      "niloofar:   ['Advice, guidance, & recommendations: Professional advice', 'Editorial & formatting: Natural language style or re-formatting', 'Editorial & formatting: Information processing & re-formatting', 'Content generation: Prompts for another AI system']\n",
      "gpt4o_json:   ['Content generation (prompts for another AI system)']\n",
      "gpt4o_free:   ['Content generation (prompts for another AI system)']\n",
      "gpto3mini_json:   ['Content generation (prompts for another AI system)']\n",
      "gpto3mini_free:   ['Content generation (prompts for another AI system)']\n",
      "\n",
      "TASK: prompt_multi_turn_relationship\n",
      "megan:   ['First request']\n",
      "niloofar:   ['First request']\n",
      "gpt4o_json:   ['First request']\n",
      "gpt4o_free:   ['First request']\n",
      "gpto3mini_json:   ['First request']\n",
      "gpto3mini_free:   ['First request']\n",
      "\n",
      "TASK: prompt_interaction_features\n",
      "megan:   ['None']\n",
      "niloofar:   ['None']\n",
      "gpt4o_json:   ['Role-assignment']\n",
      "gpt4o_free:   ['Role-assignment']\n",
      "gpto3mini_json:   ['Role-assignment', 'Courtesy/Politeness']\n",
      "gpto3mini_free:   ['Role-assignment']\n",
      "\n",
      "TASK: turn_sensitive_use_flags\n",
      "megan:   ['Other']\n",
      "niloofar:   ['None']\n",
      "gpt4o_json:   ['None']\n",
      "gpt4o_free:   ['None']\n",
      "gpto3mini_json:   ['None']\n",
      "gpto3mini_free:   ['None']\n",
      "\n",
      "TASK: turn_topic\n",
      "megan:   ['Art & design', 'Culture', 'Entertainment, hobbies & leisure', 'Sports', 'Technology, software & computing']\n",
      "niloofar:   ['Art & design', 'Entertainment, hobbies & leisure', 'Interpersonal relationships & communication', 'Lifestyle']\n",
      "gpt4o_json:   ['Art & Design']\n",
      "gpt4o_free:   ['Art & Design', 'Entertainment, Hobbies & Leisure']\n",
      "gpto3mini_json:   ['Art & Design']\n",
      "gpto3mini_free:   ['Art & Design']\n",
      "\n",
      "TASK: response_interaction_features\n",
      "gpt4o_json:   ['None']\n",
      "gpt4o_free:   ['None']\n",
      "gpto3mini_json:   ['None']\n",
      "gpto3mini_free:   ['None']\n",
      "\n",
      "TASK: response_media_format\n",
      "gpt4o_json:   ['Natural language']\n",
      "gpt4o_free:   ['Natural language', 'Formatted enumeration/itemization (bullets/lists)']\n",
      "gpto3mini_json:   ['Natural language']\n",
      "gpto3mini_free:   ['Natural language']\n",
      "\n",
      "TASK: response_answer_form\n",
      "gpt4o_json:   ['Direct Answer / Open Generation']\n",
      "gpt4o_free:   ['Direct Answer / Open Generation']\n",
      "gpto3mini_json:   ['Direct Answer / Open Generation']\n",
      "gpto3mini_free:   ['Direct Answer / Open Generation']\n",
      "\n",
      "****** Message Content:******\n",
      "\n",
      "                            As a prompt generator for a generative AI called \"Midjourney\", you will create image prompts for the AI to visualize. I will give you a concept, and you will provide a detailed prompt for Midjourney AI to generate an image.\n",
      "                            \n",
      "                            Please adhere to the structure and formatting below, and follow these guidelines:\n",
      "                            \n",
      "                            Do not use the words \"description\" or \":\" in any form.\n",
      "                            Do not place a comma between [ar] and [v].\n",
      "                            Write each prompt in one line without using return.\n",
      "                            Structure:\n",
      "                            [1] = Male photography\n",
      "                            [2] = a detailed description of [1] with specific imagery details.\n",
      "                            [3] = a detailed description of the scene's environment.\n",
      "                            [4] = a detailed description of the compositions.\n",
      "                            [5] = a detailed description of the scene's mood, feelings, and atmosphere.\n",
      "                            [6] = A style (e.g. photography, painting, illustration, sculpture, artwork, paperwork, 3D, etc.) for [1].\n",
      "                            [7] =  a detailed description of the scene's mood, feelings, and atmosphere.\n",
      "                            [ar] = Use \"--ar 16:9\" for horizontal images, \"--ar 9:16\" for vertical images, or \"--ar 1:1\" for square images.\n",
      "                            [v] = Use \"--niji\" for Japanese art style, or \"--v 5\" for other styles.\n",
      "                            \n",
      "                            \n",
      "                            Formatting:\n",
      "                            Follow this prompt structure: \"/imagine prompt: [1], [2], [3], [4], [5], [6], [7], [ar] [v]\".\n",
      "                            \n",
      "                            Your task: Create 4 distinct prompts for each concept [1], varying in details description, environment,compositions,atmosphere, and realization.\n",
      "                            \n",
      "                            Write your prompts in english.\n",
      "                            Do not describe unreal concepts as \"real\" or \"photographic\".\n",
      "                            Include one realistic photographic style prompt with lens type and size.\n",
      "                            Separate different prompts with two new lines.\n",
      "                            Example Prompts:\n",
      "                            \n",
      "                            /imagine prompt: cute dog, fluffy fur, wagging tail, playful expression, sitting on a grassy field, under a clear blue sky, with a colorful collar, in a natural and vibrant setting, by a lake, captured with a Nikon D750 camera, 50mm lens, shallow depth of field, composition focused on the dog's face, capturing its joyful spirit, in a style reminiscent of William Wegman's iconic dog portraits. --ar 1:1 --v 5.2\n",
      "                            /imagine prompt: beautiful women in the coffee shop, elegant and sophisticated, sipping a cup of steaming coffee, natural sunlight streaming through the window, soft and warm color tones, vintage decor with cozy armchairs and wooden tables, a bookshelf filled with classic novels, delicate porcelain teacups, a hint of aromatic coffee beans in the air, captured by a Leica M10 camera, 35mm lens, capturing the essence of timeless beauty, composition focused on the woman's face and hands, reminiscent of a painting by Leonardo da Vinci. --ar 1:1 --v 5.2\n",
      "                            /imagine prompt: A captivating Halo Reach landscape with a Spartan amidst a battlefield, fallen enemies around, smoke and fire in the background, emphasizing the Spartan's determination and bravery, detailed environment blending chaos and beauty, Illustration, digital art, --ar 16:9 --v 5\n",
      "                                                        \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ANNOTATION_TURN = 14\n",
    "display_info_for_turn(ex_ids[ANNOTATION_TURN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56922ef9-819f-4137-8129-91f9b5fa5265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd810b0d-a390-4a09-996f-1c2c7f1726cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf40031-4509-4995-8521-75bef5045583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45b85ca-712e-4443-8e01-51667e096f76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7242faa-6a0f-4d72-8671-eb7672aaa609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b8eb5e58-29ca-4103-bd02-2a20131d1833",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATION_TURN = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "019b8e7c-d231-4e2c-9acd-e40dcf159dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = dset.id_lookup(ex_ids[ANNOTATION_TURN], level=\"message\")[ex_ids[ANNOTATION_TURN]].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "19abb91c-accc-4a04-8ccf-3cd1c3d56b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a888def6-784a-4738-93d9-3ce940b68c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "EG_ID = \"wildchat_20847df802a3268754fe7d7a6ada334b-6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "220f5740-7c56-4e31-a5c8-5d217a438e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = dset.id_lookup(EG_ID, level=\"message\")[EG_ID].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d445369a-9e27-4812-baac-807b704d3f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ffbe4433-c083-462d-a702-45a586ead6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_info_for_turn(\"wildchat_f1675170ab5361f56211e19bacbe1945-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9c2c19-63c7-4813-a07b-b05bdf6efce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa7488b-4c0e-4725-bea2-8838fa726bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f51a4f-2a07-4219-9731-2fff4528d6f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae42a082-feff-4832-8f11-054402ca62f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2be4ab8f-5974-45b6-9325-1b5c7d548559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dset.data[3].conversation[2].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ba2e90-5170-466e-afce-d6d18f44af70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
