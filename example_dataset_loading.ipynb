{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Download both benchmarks, format them, and save them to the `data` directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Download for HLE (Humanity's Last Exam)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Humanity's Last Exam: 100%|██████████| 2500/2500 [00:00<00:00, 786156.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 2500 conversations to datasets/hle/full.json...\n",
      "Starting Download for MMLU...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing MMLU Categories: 100%|██████████| 57/57 [00:39<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 14042 conversations to datasets/mmlu/full.json...\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"./\")\n",
    "sys.path.append(\"src/\")\n",
    "sys.path.append(\"src/scripts/\")\n",
    "\n",
    "from download_datasets import download_dataset \n",
    "\n",
    "# Define the datasets you want to process\n",
    "datasets = [\"hle\", \"mmlu\"]\n",
    "\n",
    "# Loop through each dataset and download it. This will automatically save in the dataset_downloads folder. \n",
    "for dataset_id in datasets:\n",
    "    download_dataset(\n",
    "        dataset_id=dataset_id\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load the datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 datasets that meet the desired specifications: ['hle', 'mmlu']. Loading them from data files...\n"
     ]
    }
   ],
   "source": [
    "from src.scripts.load_datasets import load_datasets\n",
    "[hle, mmlu] = load_datasets(by = \"id\", ids = [\"hle\", \"mmlu\"], path_to_dataset_downloads=\"datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversation_id': 'hle_6687ffb1091058ff19128813',\n",
       " 'dataset_id': 'hle',\n",
       " 'user_id': 'Elliott T',\n",
       " 'time': '02/11/2025',\n",
       " 'model': None,\n",
       " 'geography': 'Unknown',\n",
       " 'metadata': {},\n",
       " 'conversation': [{'turn': 0,\n",
       "   'role': 'user',\n",
       "   'content': 'Black to move. Without moving the black queens, which sequence is mate in 2 for black, regardless of what white does? Use standard chess notation, leaving out the white move.',\n",
       "   'timestamp': None,\n",
       "   'metadata': {}}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hle.data[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversation_id': 'mmlu_4fab3f698e6f456a9064addf6b226431',\n",
       " 'dataset_id': 'mmlu',\n",
       " 'user_id': 'bbdbb17584a3400ea34b702a7dba90c1',\n",
       " 'time': None,\n",
       " 'model': None,\n",
       " 'geography': 'Unknown',\n",
       " 'metadata': {},\n",
       " 'conversation': [{'turn': 0,\n",
       "   'role': 'user',\n",
       "   'content': 'Find the degree for the given field extension Q(sqrt(2), sqrt(3), sqrt(18)) over Q. a) 0 b) 4 c) 2 d) 6',\n",
       "   'timestamp': None,\n",
       "   'metadata': {}}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmlu.data[0].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Perform any desired sampling or filtering and save to files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random sample \n",
    "import uuid \n",
    "from src.classes.dataset import Dataset\n",
    "n = 5 \n",
    "random_sample_of_converations = mmlu.random_sample(n) \n",
    "\n",
    "# Convert the random sample into a Dataset object\n",
    "dataset_name = f\"random_sample_size_{n}_id_{str(uuid.uuid4())[:5]}\"\n",
    "sampled_dataset = Dataset(dataset_id = dataset_name, data = random_sample_of_converations)\n",
    "\n",
    "# Save the dataset to a file\n",
    "sampled_dataset.save_to_json(json_path= f\"datasets/mmlu/{dataset_name}.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
